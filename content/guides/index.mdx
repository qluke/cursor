---
title: 上下文协同工作
description: 如何在Cursor中使用上下文

---

首先，什么是上下文窗口？它与在 Cursor 中高效编程有什么关系？

从更宏观的角度来看，大型语言模型（LLM）是一种通过学习海量数据集中的模式来预测和生成文本的人工智能模型。它为像 Cursor 这样的工具提供支持，通过理解你的输入并根据以往见过的内容建议代码或文本。

Token（标记）是这些模型的输入和输出。它们是文本的片段，通常是单词的一部分，LLM 会逐个处理这些 token。模型不会一次性读取完整句子，而是根据前面的 token 预测下一个 token。

要查看一段文本如何被分词，你可以使用像[这个](https://tiktokenizer.vercel.app/)这样的分词器。

## 什么是上下文？

在 Cursor 中生成代码建议时，"上下文"指的是提供给模型的信息（以"输入 token"的形式），模型随后利用这些信息预测后续内容（以"输出 token"的形式"）。

上下文有两种类型：

1.  **意图上下文**定义了用户希望模型实现的目标。例如，系统提示通常作为用户希望模型如何表现的高层指令。在 Cursor 中，大多数"提示"属于意图上下文。"把那个按钮从蓝色变成绿色"就是陈述意图的例子；它是指令性的。
2.  **状态上下文**描述了当前世界的状态。向 Cursor 提供错误信息、控制台日志、图片和代码片段等，都是与状态相关的上下文。它是描述性的，而非指令性的。

这两种上下文协同工作，通过描述当前状态和期望的未来状态，使 Cursor 能够给出有用的编程建议。

<Mermaid
  chart="
flowchart LR
    A[意图（你想要什么）] --> C[模型]
    B[状态（事实）] --> C[模型]
    C --> D[预测]
    D --> E[行动（模型执行的操作）]
"
/>

## 在 Cursor 中提供上下文

你能为模型提供的相关上下文越多，它就越有用。如果在 Cursor 中提供的上下文不足，模型会尝试在缺乏相关信息的情况下解决问题。这通常会导致：

1.  幻觉：模型试图进行模式匹配（但实际上没有模式），从而产生意外结果。当像 `claude-3.5-sonnet` 这样的模型没有获得足够上下文时，这种情况很常见。
2.  Agent 会尝试自行收集上下文，比如搜索代码库、读取文件和调用工具。强大的推理模型（如 `claude-3.7-sonnet`）可以通过这种策略走得很远，而提供正确的初始上下文将决定后续的走向。

好消息是，Cursor 天生具备上下文感知能力，设计上就要求用户最少干预。Cursor 会自动引入模型认为相关的代码库部分，比如当前文件、其他文件中语义相似的模式，以及会话中的其他信息。

不过，可用的上下文非常多，因此手动指定你认为与任务相关的上下文，是引导模型朝正确方向前进的有效方式。

@-符号
--------

最简单的显式提供上下文的方法是使用 @-符号。当你明确知道需要包含哪个文件、文件夹、网站或其他上下文时，这种方式非常有效。越具体越好。以下是如何更精确地指定上下文的方法：

| 符号 | 示例 | 用例 | 缺点 |
| --- | --- | --- | --- |
| `@code` | `@LRUCachedFunction` | 你知道哪个函数、常量或符号与输出相关 | 需要对代码库有较深了解 |
| `@file` | `cache.ts` | 你知道需要读取或编辑哪个文件，但不确定具体位置 | 对于较大的文件，可能包含许多与任务无关的上下文 |
| `@folder` | `utils/` | 文件夹中的所有或大部分文件都相关 | 可能包含许多无关上下文 |

 

规则
-----

你可以把规则看作是希望自己或团队成员长期可用的"长期记忆"。捕捉领域特定的上下文，包括工作流、格式和其他约定，是编写规则的良好开端。

规则也可以通过 `/Generate Cursor Rules` 从现有对话生成。如果你有一段长时间的对话，包含大量提示，里面很可能有一些有用的指令或通用规则，值得后续复用。

 
MCP
---

[模型上下文协议](https://modelcontextprotocol.io/introduction) 是一个可扩展层，你可以通过它让 Cursor 执行操作并引入外部上下文。

根据你的开发环境，你可能会用到不同类型的服务器，但我们发现以下两类特别有用：

*   **内部文档**：如 Notion、Confluence、Google Docs
*   **项目管理**：如 Linear、Jira

如果你已经有通过 API 访问上下文和执行操作的工具，可以为其构建 MCP 服务器。这里有一份简短的构建指南：[https://modelcontextprotocol.io/tutorials/building-mcp-with-llms](https://modelcontextprotocol.io/tutorials/building-mcp-with-llms)。

 
自我收集上下文
----------------------

许多用户正在采用的一种强大模式是让 Agent 编写短期工具，然后运行这些工具以收集更多上下文。这在人类参与的工作流中尤其有效，你可以在代码执行前先进行审查。

例如，在代码中添加调试语句、运行代码，并让模型检查输出，这样模型就能获得它无法通过静态分析推断的动态上下文。

在 Python 中，你可以这样提示 Agent：

1.  在相关代码处添加 print("debugging: …") 语句
2.  使用终端运行代码或测试

- Agent 会读取终端输出并决定下一步操作。核心思想是让 Agent 能够访问实际的运行时行为，而不仅仅是静态代码。

要点总结
--------

 
*   上下文是高效 AI 编程的基础，包括意图（你想要什么）和状态（现有内容）。同时提供两者有助于 Cursor 做出准确预测。
*   使用 @-符号（@code、@file、@folder）精准引导 Cursor，而不是仅依赖自动上下文收集。
*   将可复用知识捕捉为规则，供团队复用，并通过模型上下文协议扩展 Cursor 能力，连接外部系统。
*   上下文不足会导致幻觉或低效，过多无关上下文则会稀释信号。找到最佳平衡以获得最佳效果。 