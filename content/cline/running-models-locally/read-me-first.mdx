---
title: 请先阅读
description: 本地运行模型须知
---

# 请先阅读

## 使用 Cline 本地运行模型：你需要了解什么 🤖

Cline 是一款强大的 AI 编码助手，利用工具调用帮助你编写、分析和修改代码。虽然本地运行模型可以节省 API 成本，但有一个重要的权衡：本地模型在使用这些关键工具时，可靠性大幅下降。

---

## 为什么本地模型表现不同？🔬

当你运行"本地版"模型时，实际上是在运行原始模型的极度简化版。这一过程称为蒸馏（distillation），就像把专业厨师的知识压缩成一本基础菜谱——保留了简单的做法，但丢失了复杂的技巧和直觉。

本地模型通过让小模型模仿大模型训练而成，但通常只保留了原始模型 1-26% 的能力。这意味着：

- 理解复杂上下文的能力大幅下降
- 多步推理能力减弱
- 工具使用能力有限
- 决策过程更为简单

可以把它想象成：用计算器运行开发环境，而不是用电脑——能处理基础任务，但复杂操作就变得不可靠甚至无法完成。

![](https://docs.cline.bot/~gitbook/image?url=https%3A%2F%2F3321249260-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252Ff8Oh1Lcy6yWYq1caYESV%252Fuploads%252FFKMggfQCHRttZWr7EGSW%252Fimage.png%3Falt%3Dmedia%26token%3D3b8e11ac-40a6-448b-8bba-61c1a0ba29d8&width=768&dpr=4&quality=100&sign=5b6b778d&sv=2)

## 实际会发生什么？

### 性能影响 📉

- 响应速度比云服务慢 5-10 倍
- 系统资源（CPU、GPU、内存）占用高
- 电脑可能变得不适合其他任务

### 工具可靠性问题 🛠️

- 代码分析准确性下降
- 文件操作可能不可靠
- 浏览器自动化能力减弱
- 终端命令失败概率增加
- 复杂多步任务容易中断

## 硬件要求 💻

最低建议配置：

- 8GB+ 显存的现代 GPU（如 RTX 3070 或更高）
- 32GB+ 系统内存
- 快速 SSD 存储
- 良好的散热系统

即使有这些硬件，你运行的也只是更小、更弱的模型版本：

| 模型规模 | 能力描述 |
| --- | --- |
| 7B | 基础编码，工具使用有限 |
| 14B | 编码能力提升，工具使用不稳定 |
| 32B | 编码良好，工具使用不一致 |
| 70B | 本地最佳表现，但需昂贵硬件 |

简单来说，云端（API）模型才是完整体。例如 DeepSeek-R1 的完整版为 671B。本地蒸馏模型本质上是"缩水版"。

## 实用建议 💡

### 推荐做法

1. 云端模型适合：
   - 复杂开发任务
   - 工具可靠性要求高
   - 多步操作
   - 关键代码变更
2. 本地模型适合：
   - 简单代码补全
   - 基础文档生成
   - 隐私要求极高
   - 学习和实验

### 如果你必须本地运行

- 从小模型开始
- 保持任务简单聚焦
- 经常保存工作
- 复杂操作随时切换云端模型
- 监控系统资源

## 常见问题 🚨

- **"工具执行失败"：** 本地模型常常难以处理复杂工具链。请简化你的提示。
- **"无法建立连接，目标机器主动拒绝"：** 通常是 Ollama 或 LM Studio 服务未运行，或端口/地址配置不正确。请检查 API Provider 设置中的 Base URL。
- **"Cline 出现问题..."**：请将模型上下文长度调至最大。
- **响应慢或不完整：** 本地模型比云端慢，尤其在硬件较弱时。可尝试更小模型，预计处理时间会更长。
- **系统稳定性：** 注意 GPU/CPU 占用和温度
- **上下文限制：** 本地模型上下文窗口通常小于云端。请将任务拆分为更小部分。

## 展望未来 🔮

本地模型能力正在提升，但目前还无法完全替代云服务，尤其是在 Cline 的工具功能方面。请根据自身需求和硬件能力谨慎选择是否只用本地模型。

## 需要帮助？🤝

- 加入我们的 [Discord](https://discord.gg/cline) 社区和 [r/cline](https://www.reddit.com/r/CLine/)
- 查看最新兼容性指南
- 与其他开发者分享你的经验

> 温馨提示：遇到重要开发任务时，请优先选择可靠性高于节省成本。


